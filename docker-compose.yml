version: "3.9"
services:
  zoo1:
    image: confluentinc/cp-zookeeper:latest
    hostname: zoo1
    container_name: zoo1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zoo1:2888:3888;zoo2:2888:3888;zoo3:2888:3888
    ports:
      - "2181:2181"
    volumes:
      - ./data/zoo1/data:/var/lib/zookeeper/data
      - ./data/zoo1/log:/var/lib/zookeeper/log
    networks:
      - hadoop_network

  zoo2:
    image: confluentinc/cp-zookeeper:latest
    hostname: zoo2
    container_name: zoo2
    ports:
      - "2182:2182"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2182
      ZOOKEEPER_SERVER_ID: 2
      ZOOKEEPER_SERVERS: zoo1:2888:3888;zoo2:2888:3888;zoo3:2888:3888
    volumes:
      - ./data/zoo2/data:/var/lib/zookeeper/data
      - ./data/zoo2/log:/var/lib/zookeeper/log
    networks:
      - hadoop_network
  zoo3:
    image: confluentinc/cp-zookeeper:latest
    hostname: zoo3
    container_name: zoo3
    ports:
      - "2183:2183"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2183
      ZOOKEEPER_SERVER_ID: 3
      ZOOKEEPER_SERVERS: zoo1:2888:3888;zoo2:2888:3888;zoo3:2888:3888
    volumes:
      - ./data/zoo3/data:/var/lib/zookeeper/data
      - ./data/zoo3/log:/var/lib/zookeeper/log
    networks:
      - hadoop_network

  kafka1:
    image: confluentinc/cp-kafka:latest
    hostname: kafka1
    container_name: kafka1
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181,zoo2:2182,zoo3:2183"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    depends_on:
      - zoo1
      - zoo2
      - zoo3
    volumes:
      - ./data/kafka1:/var/lib/kafka/data
    networks:
      - hadoop_network

  kafka2:
    image: confluentinc/cp-kafka:latest
    hostname: kafka2
    container_name: kafka2
    ports:
      - "9093:9093"
      - "29093:29093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka2:19093,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9093,DOCKER://host.docker.internal:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181,zoo2:2182,zoo3:2183"
      KAFKA_BROKER_ID: 2
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    depends_on:
      - zoo1
      - zoo2
      - zoo3
    volumes:
      - ./data/kafka2:/var/lib/kafka/data
    networks:
      - hadoop_network

  kafka3:
    image: confluentinc/cp-kafka:latest
    hostname: kafka3
    container_name: kafka3
    ports:
      - "9094:9094"
      - "29094:29094"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka3:19094,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9094,DOCKER://host.docker.internal:29094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181,zoo2:2182,zoo3:2183"
      KAFKA_BROKER_ID: 3
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    depends_on:
      - zoo1
      - zoo2
      - zoo3
    volumes:
      - ./data/kafka3:/var/lib/kafka/data
    networks:
      - hadoop_network

  namenode:
    image: bde2020/hadoop-namenode:latest
    container_name: namenode
    volumes:
      - ./hadoop_namenode:/hadoop/dfs/name
      - ./data/:/hadoop-data/input
      - ./map_reduce/:/hadoop-data/map_reduce
      - ./requirements.txt:/requirements.txt
    environment:
      - CLUSTER_NAME=vnstock
    env_file:
      - ./hadoop.env
    ports:
      - "9870:9870"
      - "8020:8020"
    networks:
      - hadoop_network

  datanode1:
    image: bde2020/hadoop-datanode:latest
    container_name: datanode1
    depends_on:
      - namenode
    volumes:
      - ./hadoop_datanode1:/hadoop/dfs/data
    env_file:
      - ./hadoop.env
    networks:
      - hadoop_network

  datanode2:
    image: bde2020/hadoop-datanode:latest
    container_name: datanode2
    depends_on:
      - namenode
    volumes:
      - ./hadoop_datanode2:/hadoop/dfs/data
    env_file:
      - ./hadoop.env
    networks:
      - hadoop_network

  datanode3:
    image: bde2020/hadoop-datanode:latest
    container_name: datanode3
    depends_on:
      - namenode
    volumes:
      - ./hadoop_datanode3:/hadoop/dfs/data
    env_file:
      - ./hadoop.env
    networks:
      - hadoop_network

  spark-master:
    image: bde2020/spark-master:latest
    ports:
      - "9090:8081"
      - "7077:7077"
    volumes:
       - ./spark/apps:/opt/spark-apps
       - ./spark/data:/opt/spark-data
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_WORKLOAD=master
      - INIT_DAEMON_STEP=setup_spark
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    networks:
      - hadoop_network

  spark-worker:
    image: bde2020/spark-worker:latest
    ports:
      - "9091:8081"
      - "7000:7000"
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    volumes:
      - ./spark/apps:/opt/spark-apps
      - ./spark/data:/opt/spark-data
    networks:
      - hadoop_network
  cassandra:
    image: cassandra:latest
    container_name: cassandra
    hostname: cassandra
    env_file:
      - src/cassandra/cassandra.env
    ports:
      - "9042:9042"
    volumes:
      - ./cassandra:/var/lib/cassandra
    networks:
      - hadoop_network


networks:
  hadoop_network:
      driver: bridge
      external: true
